{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score\n",
    "import skfuzzy as fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "%matplotlib qt5\n",
    "plt.rcParams['figure.dpi'] = 120"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    data = pd.read_csv(\"e-shop data and description/e-shop clothing 2008.csv\", delimiter=\";\")\n",
    "    data = data.drop(['year', 'page 2 (clothing model)'], axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data, verbose=True):\n",
    "    scaler = StandardScaler()\n",
    "    normalized_data = pd.DataFrame(data=scaler.fit_transform(data), columns=data.columns)\n",
    "    for column in normalized_data.columns:\n",
    "        if verbose:\n",
    "            print(column, \"column mean value is:\", normalized_data[column].mean())\n",
    "    print()\n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimension reduction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def pca2components(data, verbose=True):\n",
    "    pca = PCA(n_components=2)\n",
    "    principal_components = pca.fit_transform(data)\n",
    "    data = pd.DataFrame(data=principal_components, columns = ['dim 1', 'dim 2'])\n",
    "    data.plot.scatter('dim 1', 'dim 2', s=10)\n",
    "    if verbose:\n",
    "        print(pca.explained_variance_ratio_)\n",
    "        print(\"\\n total variance:\", str(int((sum(pca.explained_variance_ratio_)*100))) + \"%\", \"\\n\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering methods:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### performing k-means and computing wss and silhouette score\n",
    "WSS stands for Within-Cluster-Sum of Squared Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means_optimization(data, max_k, verbose=True):\n",
    "    wss = []\n",
    "    s = []\n",
    "    for k in range(1, max_k + 1):\n",
    "        if verbose:\n",
    "            print(\"computing with k =\",k, end=' ')\n",
    "        kmeans = KMeans(n_clusters=k, algorithm='full').fit(data)\n",
    "        wss_k = kmeans.inertia_\n",
    "        wss.append((k, wss_k))\n",
    "        if k != 1:\n",
    "            s_k = silhouette_score(data, labels=kmeans.labels_, sample_size=3000, random_state=100)\n",
    "            s.append((k, s_k))\n",
    "            if verbose:\n",
    "                print(\"--> wss:\", wss_k, \"silhouette:\", s_k)\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(\"--> wss:\", wss_k)\n",
    "    print('done')\n",
    "    return (wss, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_k_means_optimization(test_name: str, test_df, max_k: int, lfs=10, tfs=8):\n",
    "    test_df = pd.DataFrame(data=test_df, columns=['k',test_name])\n",
    "    test_ax = test_df.plot(x='k',y=test_name)\n",
    "    test_ax.set_xlabel('k clusters', fontsize=lfs)\n",
    "    test_ax.set_ylabel(test_name.replace('_', ' '), fontsize=lfs)\n",
    "    test_ax.set_xticks(range(2, max_k, 2))\n",
    "    for tick in test_ax.xaxis.get_major_ticks() + test_ax.yaxis.get_major_ticks():\n",
    "        tick.label.set_fontsize(tfs) \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs=10 #label font_size\n",
    "tfs=8 #tick font_size\n",
    "# %matplotlib inline\n",
    "%matplotlib qt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_color(label):\n",
    "    colors = ['b', 'g', 'r', 'c', 'm', '#fdff03', '#055803', '#a6fc00', '#9d70d1', '#ff703b', '#3a70d8', '#ff70b5']\n",
    "    return colors[label % len(colors)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clusters(data, labels, n_clusters, lfs=10, tfs=8):\n",
    "    for label in range(n_clusters):\n",
    "        plt.scatter(data.values[labels==label, 0], data.values[labels==label, 1], s=40, c=cluster_color(label))\n",
    "    clusters_ax = plt.gca()\n",
    "    clusters_ax.set_xlabel('dim1', fontsize=lfs)\n",
    "    clusters_ax.set_ylabel('dim2', fontsize=lfs)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means(n_clusters: int):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, algorithm='full')\n",
    "    labels = kmeans.fit_predict(data)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmm(n_clusters: int):\n",
    "    gmm = GaussianMixture(n_components=n_clusters, covariance_type='full', init_params='kmeans'\n",
    "                          , warm_start=True, n_init=3, random_state=100, verbose=2)\n",
    "    gmm.fit(data)\n",
    "    labels = gmm.predict(data)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzy(fuzzy_n_clusters: int):\n",
    "    cntr, u, u0, d, jm, p, fpc = fuzz.cluster.cmeans(data.T.values, fuzzy_n_clusters, 2, error=0.005, maxiter=1000)\n",
    "    fuzzy_labels = np.argmax(u, axis=0)\n",
    "    return fuzzy_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocess:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data = read_data()\n",
    "data = normalize(data, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dimension reduction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pca2components(data, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means\n",
    "We choose the optimum k by looking at the WSS and the Silhouette score graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "max_k = 20\n",
    "wss, s = k_means_optimization(data, max_k, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_k_means_optimization(test_name='wss_error', test_df=wss, max_k=max_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_k_means_optimization(test_name='silhouette', test_df=s, max_k=max_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "km_clusters = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_means_labels = k_means(k=km_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization 0\n",
      "Initialization converged: True\t time lapse 6.60234s\t ll -3.37332\n",
      "Initialization 1\n",
      "  Iteration 10\t time lapse 6.91945s\t ll change 0.00102\n",
      "Initialization converged: True\t time lapse 7.47511s\t ll -3.37711\n",
      "Initialization 2\n",
      "  Iteration 10\t time lapse 5.88326s\t ll change 0.00103\n",
      "Initialization converged: True\t time lapse 6.21526s\t ll -3.38396\n"
     ]
    }
   ],
   "source": [
    "gmm_clusters = 8\n",
    "gmm_labels = gmm(gmm_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fuzzy c-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzy_clusters = 6\n",
    "fuzzy_labels = fuzzy(fuzzy_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tombe\\anaconda3\\lib\\site-packages\\ipykernel\\eventloops.py:106: UserWarning: Attempting to set identical left == right == -1.3718646733526474 results in singular transformations; automatically expanding.\n",
      "  app.exec_()\n"
     ]
    }
   ],
   "source": [
    "plot_clusters(data, k_means_labels, n_clusters=km_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_clusters(data, gmm_labels, n_clusters=gmm_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_clusters(data, fuzzy_labels, n_clusters=fuzzy_clusters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
